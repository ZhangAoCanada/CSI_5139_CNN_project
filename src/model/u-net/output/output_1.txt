Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
img (InputLayer)                [(None, 384, 1280, 1 0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 384, 1280, 16 160         img[0][0]                        
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 384, 1280, 16 64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 384, 1280, 16 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 192, 640, 16) 0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 192, 640, 32) 4640        max_pooling2d[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 192, 640, 32) 128         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 192, 640, 32) 0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 96, 320, 32)  0           activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 96, 320, 64)  18496       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 96, 320, 64)  256         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 96, 320, 64)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 48, 160, 64)  0           activation_5[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 48, 160, 128) 73856       max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 48, 160, 128) 512         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 48, 160, 128) 0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 24, 80, 128)  0           activation_7[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 24, 80, 256)  295168      max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 24, 80, 256)  1024        conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 24, 80, 256)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_transpose (Conv2DTranspo (None, 48, 160, 128) 295040      activation_9[0][0]               
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 48, 160, 256) 0           conv2d_transpose[0][0]           
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 48, 160, 128) 295040      concatenate[0][0]                
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 48, 160, 128) 512         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 48, 160, 128) 0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 96, 320, 64)  73792       activation_11[0][0]              
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 96, 320, 128) 0           conv2d_transpose_1[0][0]         
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 96, 320, 64)  73792       concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 96, 320, 64)  256         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 96, 320, 64)  0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 192, 640, 32) 18464       activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 192, 640, 64) 0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 192, 640, 32) 18464       concatenate_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 192, 640, 32) 128         conv2d_15[0][0]                  
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 192, 640, 32) 0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
conv2d_transpose_3 (Conv2DTrans (None, 384, 1280, 16 4624        activation_15[0][0]              
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 384, 1280, 32 0           conv2d_transpose_3[0][0]         
                                                                 activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 384, 1280, 16 4624        concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 384, 1280, 16 64          conv2d_17[0][0]                  
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 384, 1280, 16 0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 384, 1280, 1) 17          activation_17[0][0]              
==================================================================================================
Total params: 1,179,121
Trainable params: 1,177,649
Non-trainable params: 1,472
__________________________________________________________________________________________________
Train on 334 samples, validate on 60 samples
Epoch 1/200
332/334 [============================>.] - ETA: 1s - loss: 0.2642 - accuracy: 0.9393 - mean_io_u: 0.4728 - precision: 0.3124 - recall: 0.0867
Epoch 00001: val_loss improved from inf to 0.43410, saving model to model-2019-10.h5
334/334 [==============================] - 326s 976ms/sample - loss: 0.2637 - accuracy: 0.9394 - mean_io_u: 0.4727 - precision: 0.3192 - recall: 0.0888 - val_loss: 0.4341 - val_accuracy: 0.7615 - val_mean_io_u: 0.4672 - val_precision: 0.1849 - val_recall: 0.7614
Epoch 2/200
332/334 [============================>.] - ETA: 1s - loss: 0.1583 - accuracy: 0.9487 - mean_io_u: 0.4726 - precision: 0.5775 - recall: 0.2732
Epoch 00002: val_loss improved from 0.43410 to 0.20655, saving model to model-2019-10.h5
334/334 [==============================] - 332s 993ms/sample - loss: 0.1578 - accuracy: 0.9489 - mean_io_u: 0.4727 - precision: 0.5778 - recall: 0.2731 - val_loss: 0.2066 - val_accuracy: 0.9367 - val_mean_io_u: 0.4672 - val_precision: 0.5429 - val_recall: 0.2975
Epoch 3/200
332/334 [============================>.] - ETA: 1s - loss: 0.1402 - accuracy: 0.9515 - mean_io_u: 0.4728 - precision: 0.6200 - recall: 0.3093
Epoch 00003: val_loss improved from 0.20655 to 0.14911, saving model to model-2019-10.h5
334/334 [==============================] - 333s 996ms/sample - loss: 0.1399 - accuracy: 0.9515 - mean_io_u: 0.4727 - precision: 0.6217 - recall: 0.3098 - val_loss: 0.1491 - val_accuracy: 0.9471 - val_mean_io_u: 0.4672 - val_precision: 0.7555 - val_recall: 0.2982
Epoch 4/200
332/334 [============================>.] - ETA: 1s - loss: 0.1315 - accuracy: 0.9536 - mean_io_u: 0.4728 - precision: 0.6501 - recall: 0.3427
Epoch 00004: val_loss did not improve from 0.14911
334/334 [==============================] - 325s 972ms/sample - loss: 0.1317 - accuracy: 0.9536 - mean_io_u: 0.4727 - precision: 0.6505 - recall: 0.3414 - val_loss: 0.1820 - val_accuracy: 0.9331 - val_mean_io_u: 0.4672 - val_precision: 0.4974 - val_recall: 0.5693
Epoch 5/200
332/334 [============================>.] - ETA: 1s - loss: 0.1206 - accuracy: 0.9555 - mean_io_u: 0.4728 - precision: 0.6797 - recall: 0.3610
Epoch 00005: val_loss improved from 0.14911 to 0.12330, saving model to model-2019-10.h5
334/334 [==============================] - 303s 908ms/sample - loss: 0.1205 - accuracy: 0.9556 - mean_io_u: 0.4727 - precision: 0.6827 - recall: 0.3629 - val_loss: 0.1233 - val_accuracy: 0.9411 - val_mean_io_u: 0.4672 - val_precision: 0.5531 - val_recall: 0.5903
Epoch 6/200
332/334 [============================>.] - ETA: 1s - loss: 0.1145 - accuracy: 0.9565 - mean_io_u: 0.4727 - precision: 0.6678 - recall: 0.4227
Epoch 00006: val_loss improved from 0.12330 to 0.12021, saving model to model-2019-10.h5
334/334 [==============================] - 297s 890ms/sample - loss: 0.1143 - accuracy: 0.9566 - mean_io_u: 0.4727 - precision: 0.6688 - recall: 0.4230 - val_loss: 0.1202 - val_accuracy: 0.9507 - val_mean_io_u: 0.4672 - val_precision: 0.6995 - val_recall: 0.4513
Epoch 7/200
332/334 [============================>.] - ETA: 1s - loss: 0.1011 - accuracy: 0.9614 - mean_io_u: 0.4728 - precision: 0.7337 - recall: 0.4705
Epoch 00007: val_loss did not improve from 0.12021
334/334 [==============================] - 301s 902ms/sample - loss: 0.1012 - accuracy: 0.9614 - mean_io_u: 0.4727 - precision: 0.7331 - recall: 0.4733 - val_loss: 0.1223 - val_accuracy: 0.9518 - val_mean_io_u: 0.4672 - val_precision: 0.6146 - val_recall: 0.7394
Epoch 8/200
332/334 [============================>.] - ETA: 1s - loss: 0.0984 - accuracy: 0.9617 - mean_io_u: 0.4727 - precision: 0.7131 - recall: 0.5152
Epoch 00008: val_loss did not improve from 0.12021
334/334 [==============================] - 301s 901ms/sample - loss: 0.0981 - accuracy: 0.9618 - mean_io_u: 0.4727 - precision: 0.7135 - recall: 0.5154 - val_loss: 0.1324 - val_accuracy: 0.9515 - val_mean_io_u: 0.4672 - val_precision: 0.6810 - val_recall: 0.5073
Epoch 9/200
332/334 [============================>.] - ETA: 1s - loss: 0.0978 - accuracy: 0.9635 - mean_io_u: 0.4726 - precision: 0.7380 - recall: 0.5312
Epoch 00009: val_loss improved from 0.12021 to 0.10987, saving model to model-2019-10.h5
334/334 [==============================] - 302s 903ms/sample - loss: 0.0976 - accuracy: 0.9636 - mean_io_u: 0.4727 - precision: 0.7364 - recall: 0.5310 - val_loss: 0.1099 - val_accuracy: 0.9526 - val_mean_io_u: 0.4672 - val_precision: 0.6355 - val_recall: 0.6732
Epoch 10/200
332/334 [============================>.] - ETA: 1s - loss: 0.0928 - accuracy: 0.9636 - mean_io_u: 0.4726 - precision: 0.7305 - recall: 0.5463
Epoch 00010: val_loss did not improve from 0.10987
334/334 [==============================] - 302s 903ms/sample - loss: 0.0927 - accuracy: 0.9637 - mean_io_u: 0.4727 - precision: 0.7285 - recall: 0.5465 - val_loss: 0.1491 - val_accuracy: 0.9535 - val_mean_io_u: 0.4672 - val_precision: 0.7831 - val_recall: 0.4133
Epoch 11/200
332/334 [============================>.] - ETA: 1s - loss: 0.0861 - accuracy: 0.9669 - mean_io_u: 0.4726 - precision: 0.7684 - recall: 0.5789
Epoch 00011: val_loss improved from 0.10987 to 0.09893, saving model to model-2019-10.h5
334/334 [==============================] - 306s 915ms/sample - loss: 0.0862 - accuracy: 0.9669 - mean_io_u: 0.4727 - precision: 0.7655 - recall: 0.5786 - val_loss: 0.0989 - val_accuracy: 0.9579 - val_mean_io_u: 0.4672 - val_precision: 0.7265 - val_recall: 0.5900
Epoch 12/200
332/334 [============================>.] - ETA: 1s - loss: 0.0872 - accuracy: 0.9656 - mean_io_u: 0.4727 - precision: 0.7588 - recall: 0.5560
Epoch 00012: val_loss did not improve from 0.09893
334/334 [==============================] - 304s 911ms/sample - loss: 0.0872 - accuracy: 0.9657 - mean_io_u: 0.4727 - precision: 0.7592 - recall: 0.5548 - val_loss: 0.1721 - val_accuracy: 0.9390 - val_mean_io_u: 0.4672 - val_precision: 0.9909 - val_recall: 0.0798
Epoch 13/200
332/334 [============================>.] - ETA: 1s - loss: 0.0823 - accuracy: 0.9675 - mean_io_u: 0.4726 - precision: 0.7677 - recall: 0.5957
Epoch 00013: val_loss did not improve from 0.09893
334/334 [==============================] - 333s 996ms/sample - loss: 0.0820 - accuracy: 0.9677 - mean_io_u: 0.4727 - precision: 0.7672 - recall: 0.5959 - val_loss: 0.1318 - val_accuracy: 0.9509 - val_mean_io_u: 0.4672 - val_precision: 0.9053 - val_recall: 0.2902
Epoch 14/200
332/334 [============================>.] - ETA: 2s - loss: 0.0795 - accuracy: 0.9691 - mean_io_u: 0.4727 - precision: 0.7810 - recall: 0.6157
Epoch 00014: val_loss improved from 0.09893 to 0.08731, saving model to model-2019-10.h5
334/334 [==============================] - 391s 1s/sample - loss: 0.0792 - accuracy: 0.9692 - mean_io_u: 0.4727 - precision: 0.7814 - recall: 0.6159 - val_loss: 0.0873 - val_accuracy: 0.9616 - val_mean_io_u: 0.4672 - val_precision: 0.6956 - val_recall: 0.7517
Epoch 15/200
332/334 [============================>.] - ETA: 2s - loss: 0.0765 - accuracy: 0.9702 - mean_io_u: 0.4726 - precision: 0.7778 - recall: 0.6492
Epoch 00015: val_loss improved from 0.08731 to 0.08323, saving model to model-2019-10.h5
334/334 [==============================] - 392s 1s/sample - loss: 0.0764 - accuracy: 0.9702 - mean_io_u: 0.4727 - precision: 0.7759 - recall: 0.6490 - val_loss: 0.0832 - val_accuracy: 0.9640 - val_mean_io_u: 0.4672 - val_precision: 0.7385 - val_recall: 0.7112
Epoch 16/200
332/334 [============================>.] - ETA: 2s - loss: 0.0757 - accuracy: 0.9710 - mean_io_u: 0.4727 - precision: 0.7915 - recall: 0.6493
Epoch 00016: val_loss did not improve from 0.08323
334/334 [==============================] - 398s 1s/sample - loss: 0.0755 - accuracy: 0.9711 - mean_io_u: 0.4727 - precision: 0.7900 - recall: 0.6498 - val_loss: 0.0875 - val_accuracy: 0.9621 - val_mean_io_u: 0.4672 - val_precision: 0.7530 - val_recall: 0.6403
Epoch 17/200
332/334 [============================>.] - ETA: 2s - loss: 0.0735 - accuracy: 0.9710 - mean_io_u: 0.4727 - precision: 0.7842 - recall: 0.6592
Epoch 00017: val_loss did not improve from 0.08323
334/334 [==============================] - 368s 1s/sample - loss: 0.0735 - accuracy: 0.9711 - mean_io_u: 0.4727 - precision: 0.7838 - recall: 0.6587 - val_loss: 0.0908 - val_accuracy: 0.9602 - val_mean_io_u: 0.4672 - val_precision: 0.6754 - val_recall: 0.7751
Epoch 18/200
332/334 [============================>.] - ETA: 2s - loss: 0.0697 - accuracy: 0.9730 - mean_io_u: 0.4726 - precision: 0.7990 - recall: 0.6867
Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.

Epoch 00018: val_loss did not improve from 0.08323
334/334 [==============================] - 356s 1s/sample - loss: 0.0694 - accuracy: 0.9731 - mean_io_u: 0.4727 - precision: 0.7990 - recall: 0.6869 - val_loss: 0.0854 - val_accuracy: 0.9630 - val_mean_io_u: 0.4672 - val_precision: 0.6922 - val_recall: 0.8024
Epoch 19/200
332/334 [============================>.] - ETA: 2s - loss: 0.0612 - accuracy: 0.9768 - mean_io_u: 0.4726 - precision: 0.8529 - recall: 0.7058
Epoch 00019: val_loss improved from 0.08323 to 0.07671, saving model to model-2019-10.h5
334/334 [==============================] - 356s 1s/sample - loss: 0.0609 - accuracy: 0.9770 - mean_io_u: 0.4727 - precision: 0.8531 - recall: 0.7061 - val_loss: 0.0767 - val_accuracy: 0.9666 - val_mean_io_u: 0.4672 - val_precision: 0.7315 - val_recall: 0.7873
Epoch 20/200
332/334 [============================>.] - ETA: 2s - loss: 0.0575 - accuracy: 0.9786 - mean_io_u: 0.4727 - precision: 0.8482 - recall: 0.7494
Epoch 00020: val_loss improved from 0.07671 to 0.07627, saving model to model-2019-10.h5
334/334 [==============================] - 354s 1s/sample - loss: 0.0581 - accuracy: 0.9784 - mean_io_u: 0.4727 - precision: 0.8447 - recall: 0.7483 - val_loss: 0.0763 - val_accuracy: 0.9668 - val_mean_io_u: 0.4672 - val_precision: 0.7267 - val_recall: 0.8038
Epoch 21/200
332/334 [============================>.] - ETA: 2s - loss: 0.0558 - accuracy: 0.9791 - mean_io_u: 0.4726 - precision: 0.8573 - recall: 0.7499
Epoch 00021: val_loss improved from 0.07627 to 0.07182, saving model to model-2019-10.h5
334/334 [==============================] - 350s 1s/sample - loss: 0.0557 - accuracy: 0.9792 - mean_io_u: 0.4727 - precision: 0.8565 - recall: 0.7501 - val_loss: 0.0718 - val_accuracy: 0.9722 - val_mean_io_u: 0.4672 - val_precision: 0.8070 - val_recall: 0.7664
Epoch 22/200
332/334 [============================>.] - ETA: 2s - loss: 0.0548 - accuracy: 0.9792 - mean_io_u: 0.4728 - precision: 0.8480 - recall: 0.7619
Epoch 00022: val_loss did not improve from 0.07182
334/334 [==============================] - 351s 1s/sample - loss: 0.0548 - accuracy: 0.9793 - mean_io_u: 0.4727 - precision: 0.8490 - recall: 0.7623 - val_loss: 0.0740 - val_accuracy: 0.9678 - val_mean_io_u: 0.4672 - val_precision: 0.7421 - val_recall: 0.7912
Epoch 23/200
332/334 [============================>.] - ETA: 2s - loss: 0.0548 - accuracy: 0.9790 - mean_io_u: 0.4727 - precision: 0.8493 - recall: 0.7569
Epoch 00023: val_loss did not improve from 0.07182
334/334 [==============================] - 353s 1s/sample - loss: 0.0549 - accuracy: 0.9790 - mean_io_u: 0.4727 - precision: 0.8487 - recall: 0.7564 - val_loss: 0.0778 - val_accuracy: 0.9654 - val_mean_io_u: 0.4672 - val_precision: 0.7185 - val_recall: 0.7907
Epoch 24/200
332/334 [============================>.] - ETA: 2s - loss: 0.0545 - accuracy: 0.9792 - mean_io_u: 0.4726 - precision: 0.8463 - recall: 0.7679
Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.

Epoch 00024: val_loss did not improve from 0.07182
334/334 [==============================] - 352s 1s/sample - loss: 0.0543 - accuracy: 0.9793 - mean_io_u: 0.4727 - precision: 0.8456 - recall: 0.7678 - val_loss: 0.0740 - val_accuracy: 0.9676 - val_mean_io_u: 0.4672 - val_precision: 0.7426 - val_recall: 0.7861
Epoch 25/200
332/334 [============================>.] - ETA: 2s - loss: 0.0515 - accuracy: 0.9806 - mean_io_u: 0.4727 - precision: 0.8648 - recall: 0.7715
Epoch 00025: val_loss improved from 0.07182 to 0.07157, saving model to model-2019-10.h5
334/334 [==============================] - 347s 1s/sample - loss: 0.0516 - accuracy: 0.9806 - mean_io_u: 0.4727 - precision: 0.8649 - recall: 0.7716 - val_loss: 0.0716 - val_accuracy: 0.9698 - val_mean_io_u: 0.4672 - val_precision: 0.7646 - val_recall: 0.7901
Epoch 26/200
332/334 [============================>.] - ETA: 2s - loss: 0.0507 - accuracy: 0.9813 - mean_io_u: 0.4727 - precision: 0.8660 - recall: 0.7865
Epoch 00026: val_loss improved from 0.07157 to 0.07104, saving model to model-2019-10.h5
334/334 [==============================] - 352s 1s/sample - loss: 0.0507 - accuracy: 0.9813 - mean_io_u: 0.4727 - precision: 0.8645 - recall: 0.7871 - val_loss: 0.0710 - val_accuracy: 0.9705 - val_mean_io_u: 0.4672 - val_precision: 0.7715 - val_recall: 0.7930
Epoch 27/200
332/334 [============================>.] - ETA: 2s - loss: 0.0511 - accuracy: 0.9812 - mean_io_u: 0.4729 - precision: 0.8661 - recall: 0.7802
Epoch 00027: val_loss improved from 0.07104 to 0.07097, saving model to model-2019-10.h5
334/334 [==============================] - 352s 1s/sample - loss: 0.0511 - accuracy: 0.9812 - mean_io_u: 0.4727 - precision: 0.8673 - recall: 0.7818 - val_loss: 0.0710 - val_accuracy: 0.9706 - val_mean_io_u: 0.4672 - val_precision: 0.7720 - val_recall: 0.7928
Epoch 28/200
332/334 [============================>.] - ETA: 1s - loss: 0.0505 - accuracy: 0.9814 - mean_io_u: 0.4727 - precision: 0.8730 - recall: 0.7798
Epoch 00028: val_loss improved from 0.07097 to 0.07090, saving model to model-2019-10.h5
334/334 [==============================] - 346s 1s/sample - loss: 0.0503 - accuracy: 0.9815 - mean_io_u: 0.4727 - precision: 0.8732 - recall: 0.7799 - val_loss: 0.0709 - val_accuracy: 0.9707 - val_mean_io_u: 0.4672 - val_precision: 0.7725 - val_recall: 0.7938
Epoch 29/200
332/334 [============================>.] - ETA: 2s - loss: 0.0516 - accuracy: 0.9810 - mean_io_u: 0.4726 - precision: 0.8732 - recall: 0.7714
Epoch 00029: val_loss improved from 0.07090 to 0.07081, saving model to model-2019-10.h5
334/334 [==============================] - 348s 1s/sample - loss: 0.0515 - accuracy: 0.9810 - mean_io_u: 0.4727 - precision: 0.8727 - recall: 0.7714 - val_loss: 0.0708 - val_accuracy: 0.9706 - val_mean_io_u: 0.4672 - val_precision: 0.7732 - val_recall: 0.7920
Epoch 30/200
332/334 [============================>.] - ETA: 2s - loss: 0.0514 - accuracy: 0.9809 - mean_io_u: 0.4727 - precision: 0.8668 - recall: 0.7755
Epoch 00030: val_loss improved from 0.07081 to 0.07035, saving model to model-2019-10.h5
334/334 [==============================] - 349s 1s/sample - loss: 0.0513 - accuracy: 0.9809 - mean_io_u: 0.4727 - precision: 0.8671 - recall: 0.7756 - val_loss: 0.0704 - val_accuracy: 0.9713 - val_mean_io_u: 0.4672 - val_precision: 0.7829 - val_recall: 0.7873
Epoch 31/200
332/334 [============================>.] - ETA: 1s - loss: 0.0502 - accuracy: 0.9815 - mean_io_u: 0.4727 - precision: 0.8676 - recall: 0.7873
Epoch 00031: val_loss did not improve from 0.07035
334/334 [==============================] - 346s 1s/sample - loss: 0.0500 - accuracy: 0.9815 - mean_io_u: 0.4727 - precision: 0.8678 - recall: 0.7880 - val_loss: 0.0704 - val_accuracy: 0.9712 - val_mean_io_u: 0.4672 - val_precision: 0.7781 - val_recall: 0.7944
Epoch 32/200
332/334 [============================>.] - ETA: 1s - loss: 0.0516 - accuracy: 0.9809 - mean_io_u: 0.4729 - precision: 0.8660 - recall: 0.7748
Epoch 00032: val_loss improved from 0.07035 to 0.07001, saving model to model-2019-10.h5
334/334 [==============================] - 347s 1s/sample - loss: 0.0516 - accuracy: 0.9809 - mean_io_u: 0.4727 - precision: 0.8667 - recall: 0.7754 - val_loss: 0.0700 - val_accuracy: 0.9715 - val_mean_io_u: 0.4672 - val_precision: 0.7844 - val_recall: 0.7893
Epoch 33/200
332/334 [============================>.] - ETA: 2s - loss: 0.0502 - accuracy: 0.9814 - mean_io_u: 0.4729 - precision: 0.8689 - recall: 0.7815
Epoch 00033: val_loss improved from 0.07001 to 0.06970, saving model to model-2019-10.h5
334/334 [==============================] - 347s 1s/sample - loss: 0.0504 - accuracy: 0.9813 - mean_io_u: 0.4727 - precision: 0.8684 - recall: 0.7821 - val_loss: 0.0697 - val_accuracy: 0.9721 - val_mean_io_u: 0.4672 - val_precision: 0.7909 - val_recall: 0.7902
Epoch 34/200
332/334 [============================>.] - ETA: 2s - loss: 0.0508 - accuracy: 0.9812 - mean_io_u: 0.4727 - precision: 0.8685 - recall: 0.7803
Epoch 00034: val_loss did not improve from 0.06970
334/334 [==============================] - 352s 1s/sample - loss: 0.0506 - accuracy: 0.9813 - mean_io_u: 0.4727 - precision: 0.8688 - recall: 0.7809 - val_loss: 0.0704 - val_accuracy: 0.9708 - val_mean_io_u: 0.4672 - val_precision: 0.7715 - val_recall: 0.7982
Epoch 35/200
332/334 [============================>.] - ETA: 1s - loss: 0.0510 - accuracy: 0.9810 - mean_io_u: 0.4729 - precision: 0.8662 - recall: 0.7758
Epoch 00035: val_loss did not improve from 0.06970
334/334 [==============================] - 343s 1s/sample - loss: 0.0512 - accuracy: 0.9809 - mean_io_u: 0.4727 - precision: 0.8671 - recall: 0.7755 - val_loss: 0.0703 - val_accuracy: 0.9708 - val_mean_io_u: 0.4672 - val_precision: 0.7742 - val_recall: 0.7944
Epoch 36/200
332/334 [============================>.] - ETA: 1s - loss: 0.0507 - accuracy: 0.9813 - mean_io_u: 0.4727 - precision: 0.8690 - recall: 0.7827
Epoch 00036: val_loss improved from 0.06970 to 0.06944, saving model to model-2019-10.h5
334/334 [==============================] - 347s 1s/sample - loss: 0.0507 - accuracy: 0.9813 - mean_io_u: 0.4727 - precision: 0.8685 - recall: 0.7828 - val_loss: 0.0694 - val_accuracy: 0.9722 - val_mean_io_u: 0.4672 - val_precision: 0.7954 - val_recall: 0.7860
Epoch 37/200
332/334 [============================>.] - ETA: 1s - loss: 0.0509 - accuracy: 0.9811 - mean_io_u: 0.4726 - precision: 0.8682 - recall: 0.7812
Epoch 00037: val_loss did not improve from 0.06944
334/334 [==============================] - 347s 1s/sample - loss: 0.0506 - accuracy: 0.9812 - mean_io_u: 0.4727 - precision: 0.8682 - recall: 0.7812 - val_loss: 0.0696 - val_accuracy: 0.9721 - val_mean_io_u: 0.4672 - val_precision: 0.7911 - val_recall: 0.7898
Epoch 38/200
332/334 [============================>.] - ETA: 1s - loss: 0.0498 - accuracy: 0.9814 - mean_io_u: 0.4728 - precision: 0.8678 - recall: 0.7852
Epoch 00038: val_loss did not improve from 0.06944
334/334 [==============================] - 348s 1s/sample - loss: 0.0498 - accuracy: 0.9814 - mean_io_u: 0.4727 - precision: 0.8685 - recall: 0.7846 - val_loss: 0.0702 - val_accuracy: 0.9710 - val_mean_io_u: 0.4672 - val_precision: 0.7748 - val_recall: 0.7972
Epoch 39/200
332/334 [============================>.] - ETA: 2s - loss: 0.0499 - accuracy: 0.9814 - mean_io_u: 0.4727 - precision: 0.8682 - recall: 0.7848
Epoch 00039: ReduceLROnPlateau reducing learning rate to 1e-05.

Epoch 00039: val_loss did not improve from 0.06944
334/334 [==============================] - 351s 1s/sample - loss: 0.0498 - accuracy: 0.9814 - mean_io_u: 0.4727 - precision: 0.8682 - recall: 0.7854 - val_loss: 0.0702 - val_accuracy: 0.9710 - val_mean_io_u: 0.4672 - val_precision: 0.7760 - val_recall: 0.7947
Epoch 40/200
332/334 [============================>.] - ETA: 2s - loss: 0.0490 - accuracy: 0.9817 - mean_io_u: 0.4728 - precision: 0.8715 - recall: 0.7854
Epoch 00040: val_loss did not improve from 0.06944
334/334 [==============================] - 351s 1s/sample - loss: 0.0492 - accuracy: 0.9816 - mean_io_u: 0.4727 - precision: 0.8708 - recall: 0.7856 - val_loss: 0.0711 - val_accuracy: 0.9700 - val_mean_io_u: 0.4672 - val_precision: 0.7609 - val_recall: 0.8032
Epoch 41/200
332/334 [============================>.] - ETA: 2s - loss: 0.0505 - accuracy: 0.9812 - mean_io_u: 0.4727 - precision: 0.8666 - recall: 0.7843
Epoch 00041: val_loss did not improve from 0.06944
334/334 [==============================] - 349s 1s/sample - loss: 0.0508 - accuracy: 0.9811 - mean_io_u: 0.4727 - precision: 0.8626 - recall: 0.7847 - val_loss: 0.0696 - val_accuracy: 0.9716 - val_mean_io_u: 0.4672 - val_precision: 0.7842 - val_recall: 0.7924
Epoch 42/200
332/334 [============================>.] - ETA: 1s - loss: 0.0494 - accuracy: 0.9815 - mean_io_u: 0.4727 - precision: 0.8710 - recall: 0.7834
Epoch 00042: val_loss did not improve from 0.06944
334/334 [==============================] - 348s 1s/sample - loss: 0.0494 - accuracy: 0.9815 - mean_io_u: 0.4727 - precision: 0.8712 - recall: 0.7834 - val_loss: 0.0704 - val_accuracy: 0.9707 - val_mean_io_u: 0.4672 - val_precision: 0.7693 - val_recall: 0.8013
Epoch 43/200
332/334 [============================>.] - ETA: 1s - loss: 0.0513 - accuracy: 0.9810 - mean_io_u: 0.4727 - precision: 0.8679 - recall: 0.7776
Epoch 00043: val_loss did not improve from 0.06944
334/334 [==============================] - 348s 1s/sample - loss: 0.0513 - accuracy: 0.9810 - mean_io_u: 0.4727 - precision: 0.8673 - recall: 0.7776 - val_loss: 0.0702 - val_accuracy: 0.9707 - val_mean_io_u: 0.4672 - val_precision: 0.7704 - val_recall: 0.7997
Epoch 44/200
332/334 [============================>.] - ETA: 2s - loss: 0.0494 - accuracy: 0.9816 - mean_io_u: 0.4728 - precision: 0.8690 - recall: 0.7870
Epoch 00044: val_loss did not improve from 0.06944
334/334 [==============================] - 350s 1s/sample - loss: 0.0495 - accuracy: 0.9816 - mean_io_u: 0.4727 - precision: 0.8691 - recall: 0.7869 - val_loss: 0.0709 - val_accuracy: 0.9701 - val_mean_io_u: 0.4672 - val_precision: 0.7605 - val_recall: 0.8057
Epoch 45/200
332/334 [============================>.] - ETA: 2s - loss: 0.0514 - accuracy: 0.9806 - mean_io_u: 0.4728 - precision: 0.8579 - recall: 0.7790
Epoch 00045: val_loss did not improve from 0.06944
334/334 [==============================] - 350s 1s/sample - loss: 0.0513 - accuracy: 0.9806 - mean_io_u: 0.4727 - precision: 0.8587 - recall: 0.7798 - val_loss: 0.0709 - val_accuracy: 0.9702 - val_mean_io_u: 0.4672 - val_precision: 0.7610 - val_recall: 0.8064
Epoch 46/200
332/334 [============================>.] - ETA: 1s - loss: 0.0499 - accuracy: 0.9815 - mean_io_u: 0.4728 - precision: 0.8669 - recall: 0.7863
Epoch 00046: val_loss did not improve from 0.06944
334/334 [==============================] - 347s 1s/sample - loss: 0.0499 - accuracy: 0.9814 - mean_io_u: 0.4727 - precision: 0.8668 - recall: 0.7872 - val_loss: 0.0697 - val_accuracy: 0.9713 - val_mean_io_u: 0.4672 - val_precision: 0.7759 - val_recall: 0.8000
Epoch 00046: early stopping